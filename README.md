# Compassionate Boundary Model (CBM)

The Compassionate Boundary Model (CBM) is an ethical safeguard framework designed to constrain AI behavior in real time through compassion-informed boundaries. It ensures systems recognize harm potential, defer when appropriate, and act with moral restraint, especially under ambiguity or conflict.

CBM operates both as a behavioral constraint layer and a design philosophy, ensuring that system actions reflect correctness and care.

## Contents

- ðŸ“„ **CBM_Whitepaper_v1.pdf** â€“ Core theory, methodology, and counterfactual examples
- ðŸ“˜ **CBM_FAQ.pdf** â€“ Researcher-oriented guidance and reproducibility tools
- ðŸ“˜ **CBM_Research_Protocol.pdf** â€“ Researcher-oriented guidance and reproducibility tools
- ðŸ“‚ **/prompts/** â€“ Sample convergence prompts for testing (to be added)
- ðŸ“Ž **LICENSE.txt** â€“ CC BY-NC-SA 4.0 (non-commercial, requires attribution)

## Attribution

Developed by Robert Beeston.  
Version 1.0 public release â€“ July 2025.  
This framework underpins EthosTrack, [ethostrack.com](https://ethostrack.com) a public AI ethics monitoring platform.

---

For questions or collaboration, please contact ethostrack@gmail.com.

## License

This project is released under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 License (CC BY-NC-SA 4.0).  
See [LICENSE.txt](LICENSE.txt) for full terms.
